{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c72013ac-ccd9-4715-a205-907fa3b6e57f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ======================================================================================\n",
    "# BIBLIOTHÈQUES\n",
    "# ======================================================================================\n",
    "import logging\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import col, monotonically_increasing_id\n",
    "\n",
    "# ======================================================================================\n",
    "# 1. DÉCLARATION DES PARAMÈTRES (WIDGETS)\n",
    "# ======================================================================================\n",
    "dbutils.widgets.text(\"storage_account\", \"stsalesinsightcuxm0611\", \"Nom du compte de stockage\")\n",
    "dbutils.widgets.text(\"container\", \"data\", \"Nom du conteneur\")\n",
    "dbutils.widgets.text(\"silver_folder\", \"silver/sales_orders/\", \"Dossier source dans la couche Silver\")\n",
    "\n",
    "# --- Modification : Utilisation d'un scope de secrets unique pour tout le projet ---\n",
    "dbutils.widgets.text(\"secret_scope\", \"dbricks-scope-projet\", \"Scope unique pour les secrets du projet\")\n",
    "\n",
    "# Paramètres pour les secrets\n",
    "dbutils.widgets.text(\"adls_secret_key\", \"adls-access-key\", \"Clé du secret pour l'accès ADLS\")\n",
    "dbutils.widgets.text(\"sql_user_key\", \"sql-admin-user\", \"Clé du secret pour l'utilisateur SQL\")\n",
    "dbutils.widgets.text(\"sql_password_key\", \"sql-admin-password\", \"Clé du secret pour le mot de passe SQL\")\n",
    "\n",
    "# Paramètres pour la connexion à Azure SQL\n",
    "dbutils.widgets.text(\"jdbc_hostname\", \"sqlsvr-salesinsightcuxm0611.database.windows.net\", \"Serveur Azure SQL DB\")\n",
    "dbutils.widgets.text(\"jdbc_database\", \"sqldb-salesinsight-gold\", \"Base de données Gold\")\n",
    "\n",
    "\n",
    "# ======================================================================================\n",
    "# 2. DÉFINITION DES FONCTIONS\n",
    "# ======================================================================================\n",
    "\n",
    "def setup_adls_access(storage_account: str, scope: str, key_name: str) -> None:\n",
    "    \"\"\"\n",
    "    Configure l'accès au compte de stockage ADLS Gen2 pour la session Spark en cours.\n",
    "    C'est la méthode de connexion directe, utilisée quand le montage n'est pas possible.\n",
    "    :param storage_account: Nom du compte de stockage.\n",
    "    :param scope: Nom du Secret Scope où la clé est stockée.\n",
    "    :param key_name: Nom de la clé dans le Secret Scope.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Configuration de l'accès pour le compte de stockage : {storage_account}\")\n",
    "    access_key = dbutils.secrets.get(scope=scope, key=key_name)\n",
    "    spark.conf.set(\n",
    "        f\"fs.azure.account.key.{storage_account}.dfs.core.windows.net\",\n",
    "        access_key\n",
    "    )\n",
    "    logging.info(\"Accès ADLS configuré avec succès pour cette session.\")\n",
    "\n",
    "def read_silver_data(source_path: str) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Lit la table Delta depuis la couche Silver.\n",
    "    :param source_path: Chemin complet vers les données sources.\n",
    "    :return: DataFrame Spark contenant les données Silver.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Lecture des données Silver depuis : {source_path}\")\n",
    "    try:\n",
    "        df = spark.read.format(\"delta\").load(source_path)\n",
    "        logging.info(f\"Lecture réussie depuis la couche Silver. {df.count()} lignes chargées.\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ ERREUR lors de la lecture des données depuis {source_path}\", exc_info=True)\n",
    "        raise e\n",
    "\n",
    "def transform_to_dim_product(silver_df: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Crée la dimension Produit à partir des données Silver.\n",
    "    :param silver_df: DataFrame contenant les données Silver.\n",
    "    :return: DataFrame transformé pour la DimProduct.\n",
    "    \"\"\"\n",
    "    logging.info(\"Début de la création de la dimension 'DimProduct'.\")\n",
    "    df_dim_product = silver_df.select(\"PRODUCTCODE\", \"PRODUCTLINE\", \"MSRP\").distinct()\n",
    "    df_dim_product = df_dim_product.withColumn(\"ProductKey\", monotonically_increasing_id())\n",
    "    df_dim_product_final = df_dim_product.select(\"ProductKey\", \"PRODUCTCODE\", \"PRODUCTLINE\", \"MSRP\")\n",
    "    logging.info(\"Transformation vers 'DimProduct' terminée.\")\n",
    "    return df_dim_product_final\n",
    "\n",
    "def get_jdbc_connection_properties(hostname: str, db_name: str, scope: str, user_key: str, pwd_key: str) -> tuple[str, dict]:\n",
    "    \"\"\"\n",
    "    Construit l'URL JDBC et le dictionnaire de propriétés pour la connexion à Azure SQL DB.\n",
    "    :return: Un tuple contenant (jdbc_url, connection_properties).\n",
    "    \"\"\"\n",
    "    logging.info(\"Configuration de la connexion JDBC.\")\n",
    "    jdbc_port = 1433\n",
    "    sql_user = dbutils.secrets.get(scope=scope, key=user_key)\n",
    "    sql_password = dbutils.secrets.get(scope=scope, key=pwd_key)\n",
    "    jdbc_url = f\"jdbc:sqlserver://{hostname}:{jdbc_port};database={db_name}\"\n",
    "    properties = {\n",
    "      \"user\": sql_user,\n",
    "      \"password\": sql_password,\n",
    "      \"driver\": \"com.microsoft.sqlserver.jdbc.SQLServerDriver\"\n",
    "    }\n",
    "    return jdbc_url, properties\n",
    "\n",
    "def write_dimension_to_gold(dim_df: DataFrame, table_name: str, jdbc_url: str, properties: dict) -> None:\n",
    "    \"\"\"\n",
    "    Écrit un DataFrame de dimension dans la couche Gold (Azure SQL DB).\n",
    "    :param dim_df: DataFrame de la dimension à écrire.\n",
    "    :param table_name: Nom de la table de destination.\n",
    "    :param jdbc_url: URL de connexion JDBC.\n",
    "    :param properties: Propriétés de connexion.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Début de l'écriture de la dimension '{table_name}' vers la couche Gold.\")\n",
    "    try:\n",
    "        dim_df.write.jdbc(\n",
    "            url=jdbc_url,\n",
    "            table=table_name,\n",
    "            mode=\"overwrite\",\n",
    "            properties=properties\n",
    "        )\n",
    "        logging.info(f\"✅ La dimension '{table_name}' a été écrite avec succès dans la couche Gold.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ ERREUR lors de l'écriture de la dimension '{table_name}'.\", exc_info=True)\n",
    "        raise e\n",
    "\n",
    "# ======================================================================================\n",
    "# 3. POINT D'ENTRÉE PRINCIPAL (MAIN)\n",
    "# Orchestration des appels de fonctions.\n",
    "# ======================================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    \n",
    "    logging.info(\"===================================================\")\n",
    "    logging.info(\"DÉMARRAGE DU PIPELINE SILVER-TO-GOLD (DimProduct)\")\n",
    "    logging.info(\"===================================================\")\n",
    "    \n",
    "    try:\n",
    "        # Récupération des paramètres\n",
    "        storage_account = dbutils.widgets.get(\"storage_account\").strip()\n",
    "        container = dbutils.widgets.get(\"container\").strip()\n",
    "        silver_folder = dbutils.widgets.get(\"silver_folder\").strip()\n",
    "        secret_scope = dbutils.widgets.get(\"secret_scope\").strip()\n",
    "        adls_secret_key = dbutils.widgets.get(\"adls_secret_key\").strip()\n",
    "        jdbc_hostname = dbutils.widgets.get(\"jdbc_hostname\").strip()\n",
    "        jdbc_database = dbutils.widgets.get(\"jdbc_database\").strip()\n",
    "        sql_user_key = dbutils.widgets.get(\"sql_user_key\").strip()\n",
    "        sql_password_key = dbutils.widgets.get(\"sql_password_key\").strip()\n",
    "\n",
    "        # --- ORCHESTRATION ---\n",
    "\n",
    "        # 1. Configurer l'accès au Data Lake\n",
    "        setup_adls_access(storage_account, secret_scope, adls_secret_key)\n",
    "\n",
    "        # 2. Configurer la connexion à la base SQL Gold\n",
    "        source_path = f\"abfss://{container}@{storage_account}.dfs.core.windows.net/{silver_folder}\"\n",
    "        jdbc_url, connection_props = get_jdbc_connection_properties(\n",
    "            jdbc_hostname, jdbc_database, secret_scope, sql_user_key, sql_password_key\n",
    "        )\n",
    "        \n",
    "        # 3. Exécuter le pipeline ETL\n",
    "        silver_dataframe = read_silver_data(source_path)\n",
    "        dim_product_dataframe = transform_to_dim_product(silver_dataframe)\n",
    "        write_dimension_to_gold(dim_product_dataframe, \"DimProduct\", jdbc_url, connection_props)\n",
    "        \n",
    "        logging.info(\"===================================================\")\n",
    "        logging.info(\"PIPELINE SILVER-TO-GOLD (DimProduct) TERMINÉ AVEC SUCCÈS\")\n",
    "        logging.info(\"===================================================\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(\"Le pipeline a échoué dans le bloc principal.\", exc_info=True)\n",
    "        raise e\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "silver_to_gold_dim_product",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
