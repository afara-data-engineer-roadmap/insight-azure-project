{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ccb976b-821b-4c02-b130-6f7245d09caf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ======================================================================================\n",
    "# BIBLIOTHÈQUES\n",
    "# ======================================================================================\n",
    "import logging\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import col, min, max, sequence, to_date, explode, year, month, quarter, dayofmonth, dayofweek, date_format\n",
    "\n",
    "# ======================================================================================\n",
    "# 1. DÉCLARATION DES PARAMÈTRES (WIDGETS)\n",
    "# ======================================================================================\n",
    "dbutils.widgets.text(\"storage_account\", \"stsalesinsightcuxm0611\", \"Nom du compte de stockage\")\n",
    "dbutils.widgets.text(\"container\", \"data\", \"Nom du conteneur\")\n",
    "dbutils.widgets.text(\"silver_folder\", \"silver/sales_orders/\", \"Dossier source dans la couche Silver\")\n",
    "\n",
    "# --- Utilisation d'un scope de secrets unique pour tout le projet ---\n",
    "dbutils.widgets.text(\"secret_scope\", \"dbricks-scope-projet\", \"Scope unique pour les secrets du projet\")\n",
    "\n",
    "# Paramètres pour les clés des secrets\n",
    "# --- CORRECTION : Remplacement de 'gtext' par 'text' ---\n",
    "dbutils.widgets.text(\"adls_secret_key\", \"adls-access-key\", \"Clé du secret pour l'accès ADLS\")\n",
    "dbutils.widgets.text(\"sql_user_key\", \"sql-admin-user\", \"Clé du secret pour l'utilisateur SQL\")\n",
    "dbutils.widgets.text(\"sql_password_key\", \"sql-admin-password\", \"Clé du secret pour le mot de passe SQL\")\n",
    "\n",
    "# Paramètres pour la connexion à Azure SQL\n",
    "dbutils.widgets.text(\"jdbc_hostname\", \"sqlsvr-salesinsightcuxm0611.database.windows.net\", \"Serveur Azure SQL DB\")\n",
    "dbutils.widgets.text(\"jdbc_database\", \"sqldb-salesinsight-gold\", \"Base de données Gold\")\n",
    "\n",
    "\n",
    "# ======================================================================================\n",
    "# 2. DÉFINITION DES FONCTIONS\n",
    "# ======================================================================================\n",
    "\n",
    "def setup_adls_access(storage_account: str, scope: str, key_name: str) -> None:\n",
    "    \"\"\"\n",
    "    Configure l'accès au compte de stockage ADLS Gen2 pour la session Spark en cours.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Configuration de l'accès pour le compte de stockage : {storage_account}\")\n",
    "    access_key = dbutils.secrets.get(scope=scope, key=key_name)\n",
    "    spark.conf.set(\n",
    "        f\"fs.azure.account.key.{storage_account}.dfs.core.windows.net\",\n",
    "        access_key\n",
    "    )\n",
    "    logging.info(\"Accès ADLS configuré avec succès pour cette session.\")\n",
    "\n",
    "def read_silver_data(source_path: str) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Lit la table Delta depuis la couche Silver.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Lecture des données Silver depuis : {source_path}\")\n",
    "    try:\n",
    "        df = spark.read.format(\"delta\").load(source_path)\n",
    "        logging.info(f\"Lecture réussie depuis la couche Silver.\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ ERREUR lors de la lecture des données depuis {source_path}\", exc_info=True)\n",
    "        raise e\n",
    "\n",
    "def generate_dim_date(silver_df: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Génère une dimension de temps complète et enrichie.\n",
    "    :param silver_df: DataFrame Silver pour déterminer la plage de dates.\n",
    "    :return: DataFrame contenant la dimension de temps.\n",
    "    \"\"\"\n",
    "    logging.info(\"Début de la génération de la dimension 'DimDate'.\")\n",
    "    \n",
    "    # a. Trouver les dates min et max à partir des données de vente\n",
    "    min_max_dates = silver_df.select(\n",
    "        min(col(\"ORDERDATE\")).alias(\"MinDate\"),\n",
    "        max(col(\"ORDERDATE\")).alias(\"MaxDate\")\n",
    "    ).first()\n",
    "    \n",
    "    start_date = min_max_dates[\"MinDate\"]\n",
    "    end_date = min_max_dates[\"MaxDate\"]\n",
    "    \n",
    "    logging.info(f\"Génération des dates entre {start_date} et {end_date}.\")\n",
    "    \n",
    "    # b. Générer une séquence complète de jours entre ces deux dates\n",
    "    # C'est le cœur de la génération d'une dimension de temps robuste.\n",
    "    date_range_df = spark.sql(f\"SELECT explode(sequence(to_date('{start_date}'), to_date('{end_date}'), interval 1 day)) as FullDate\")\n",
    "\n",
    "    # c. Enrichir chaque date avec des attributs temporels utiles\n",
    "    df_dim_date = date_range_df.select(\n",
    "        col(\"FullDate\"),\n",
    "        date_format(col(\"FullDate\"), \"yyyyMMdd\").cast(\"int\").alias(\"DateKey\"), # Clé de substitution intelligente\n",
    "        year(col(\"FullDate\")).alias(\"Year\"),\n",
    "        quarter(col(\"FullDate\")).alias(\"Quarter\"),\n",
    "        month(col(\"FullDate\")).alias(\"Month\"),\n",
    "        dayofmonth(col(\"FullDate\")).alias(\"Day\"),\n",
    "        dayofweek(col(\"FullDate\")).alias(\"DayOfWeek\"),\n",
    "        date_format(col(\"FullDate\"), \"MMMM\").alias(\"MonthName\"),\n",
    "        date_format(col(\"FullDate\"), \"EEEE\").alias(\"DayName\")\n",
    "    )\n",
    "\n",
    "    # d. Réorganiser les colonnes\n",
    "    df_dim_date_final = df_dim_date.select(\n",
    "        \"DateKey\", \"FullDate\", \"Year\", \"Quarter\", \"Month\", \"Day\", \"DayOfWeek\", \"MonthName\", \"DayName\"\n",
    "    )\n",
    "    \n",
    "    logging.info(\"Génération de 'DimDate' terminée.\")\n",
    "    return df_dim_date_final\n",
    "\n",
    "def get_jdbc_connection_properties(hostname: str, db_name: str, scope: str, user_key: str, pwd_key: str) -> tuple[str, dict]:\n",
    "    \"\"\"\n",
    "    Construit l'URL JDBC et le dictionnaire de propriétés pour la connexion à Azure SQL DB.\n",
    "    \"\"\"\n",
    "    logging.info(\"Configuration de la connexion JDBC.\")\n",
    "    jdbc_port = 1433\n",
    "    sql_user = dbutils.secrets.get(scope=scope, key=user_key)\n",
    "    sql_password = dbutils.secrets.get(scope=scope, key=pwd_key)\n",
    "    jdbc_url = f\"jdbc:sqlserver://{hostname}:{jdbc_port};database={db_name}\"\n",
    "    properties = {\n",
    "      \"user\": sql_user,\n",
    "      \"password\": sql_password,\n",
    "      \"driver\": \"com.microsoft.sqlserver.jdbc.SQLServerDriver\"\n",
    "    }\n",
    "    return jdbc_url, properties\n",
    "\n",
    "def write_dimension_to_gold(dim_df: DataFrame, table_name: str, jdbc_url: str, properties: dict) -> None:\n",
    "    \"\"\"\n",
    "    Écrit un DataFrame de dimension dans la couche Gold (Azure SQL DB).\n",
    "    \"\"\"\n",
    "    logging.info(f\"Début de l'écriture de la dimension '{table_name}' vers la couche Gold.\")\n",
    "    try:\n",
    "        dim_df.write.jdbc(\n",
    "            url=jdbc_url,\n",
    "            table=table_name,\n",
    "            mode=\"overwrite\",\n",
    "            properties=properties\n",
    "        )\n",
    "        logging.info(f\"✅ La dimension '{table_name}' a été écrite avec succès dans la couche Gold.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ ERREUR lors de l'écriture de la dimension '{table_name}'.\", exc_info=True)\n",
    "        raise e\n",
    "\n",
    "# ======================================================================================\n",
    "# 3. POINT D'ENTRÉE PRINCIPAL (MAIN)\n",
    "# ======================================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    \n",
    "    logging.info(\"===================================================\")\n",
    "    logging.info(\"DÉMARRAGE DU PIPELINE SILVER-TO-GOLD (DimDate)\")\n",
    "    logging.info(\"===================================================\")\n",
    "    \n",
    "    try:\n",
    "        # Récupération des paramètres\n",
    "        storage_account = dbutils.widgets.get(\"storage_account\").strip()\n",
    "        container = dbutils.widgets.get(\"container\").strip()\n",
    "        silver_folder = dbutils.widgets.get(\"silver_folder\").strip()\n",
    "        secret_scope = dbutils.widgets.get(\"secret_scope\").strip()\n",
    "        adls_secret_key = dbutils.widgets.get(\"adls_secret_key\").strip()\n",
    "        jdbc_hostname = dbutils.widgets.get(\"jdbc_hostname\").strip()\n",
    "        jdbc_database = dbutils.widgets.get(\"jdbc_database\").strip()\n",
    "        sql_user_key = dbutils.widgets.get(\"sql_user_key\").strip()\n",
    "        sql_password_key = dbutils.widgets.get(\"sql_password_key\").strip()\n",
    "\n",
    "        # --- ORCHESTRATION ---\n",
    "        \n",
    "        # 1. Configurer l'accès au Data Lake\n",
    "        setup_adls_access(storage_account, secret_scope, adls_secret_key)\n",
    "\n",
    "        # 2. Configurer la connexion à la base SQL Gold\n",
    "        source_path = f\"abfss://{container}@{storage_account}.dfs.core.windows.net/{silver_folder}\"\n",
    "        jdbc_url, connection_props = get_jdbc_connection_properties(\n",
    "            jdbc_hostname, jdbc_database, secret_scope, sql_user_key, sql_password_key\n",
    "        )\n",
    "        \n",
    "        # 3. Exécuter le pipeline ETL pour la dimension Temps\n",
    "        silver_dataframe = read_silver_data(source_path)\n",
    "        dim_date_dataframe = generate_dim_date(silver_dataframe)\n",
    "        write_dimension_to_gold(dim_date_dataframe, \"DimDate\", jdbc_url, connection_props)\n",
    "        \n",
    "        logging.info(\"===================================================\")\n",
    "        logging.info(\"PIPELINE SILVER-TO-GOLD (DimDate) TERMINÉ AVEC SUCCÈS\")\n",
    "        logging.info(\"===================================================\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(\"Le pipeline a échoué dans le bloc principal.\", exc_info=True)\n",
    "        raise e\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "silver_to_gold_dim_date",
   "widgets": {
    "adls_secret_key": {
     "currentValue": "adls-access-key",
     "nuid": "4724a279-d86c-4bd6-a6e1-23fc63718af3",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "adls-access-key",
      "label": "Clé du secret pour l'accès ADLS",
      "name": "adls_secret_key",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "adls-access-key",
      "label": "Clé du secret pour l'accès ADLS",
      "name": "adls_secret_key",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    },
    "container": {
     "currentValue": "data",
     "nuid": "36359ef7-09ab-4da1-b1d7-340ac56e5343",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "data",
      "label": "Nom du conteneur",
      "name": "container",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "data",
      "label": "Nom du conteneur",
      "name": "container",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    },
    "jdbc_database": {
     "currentValue": "sqldb-salesinsight-gold",
     "nuid": "ce50938c-2a3a-4fe9-b0fe-7a84df7d4d50",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "sqldb-salesinsight-gold",
      "label": "Base de données Gold",
      "name": "jdbc_database",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "sqldb-salesinsight-gold",
      "label": "Base de données Gold",
      "name": "jdbc_database",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    },
    "jdbc_hostname": {
     "currentValue": "sqlsvr-salesinsightcuxm0611.database.windows.net",
     "nuid": "1e461694-882b-4950-ba40-76f60e100af5",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "sqlsvr-salesinsightcuxm0611.database.windows.net",
      "label": "Serveur Azure SQL DB",
      "name": "jdbc_hostname",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "sqlsvr-salesinsightcuxm0611.database.windows.net",
      "label": "Serveur Azure SQL DB",
      "name": "jdbc_hostname",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    },
    "secret_scope": {
     "currentValue": "dbricks-scope-projet",
     "nuid": "e376499d-9971-4843-b8a1-d78ee26607d5",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "dbricks-scope-projet",
      "label": "Scope unique pour les secrets du projet",
      "name": "secret_scope",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "dbricks-scope-projet",
      "label": "Scope unique pour les secrets du projet",
      "name": "secret_scope",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    },
    "silver_folder": {
     "currentValue": "silver/sales_orders/",
     "nuid": "739b0c89-87c6-419e-8567-1b62b72b305f",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "silver/sales_orders/",
      "label": "Dossier source dans la couche Silver",
      "name": "silver_folder",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "silver/sales_orders/",
      "label": "Dossier source dans la couche Silver",
      "name": "silver_folder",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    },
    "sql_password_key": {
     "currentValue": "sql-admin-password",
     "nuid": "a6f3ec9b-675f-4c2f-b8b0-eb4221c058a3",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "sql-admin-password",
      "label": "Clé du secret pour le mot de passe SQL",
      "name": "sql_password_key",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "sql-admin-password",
      "label": "Clé du secret pour le mot de passe SQL",
      "name": "sql_password_key",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    },
    "sql_user_key": {
     "currentValue": "sql-admin-user",
     "nuid": "aae2da23-df29-498b-8c46-d631de97e731",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "sql-admin-user",
      "label": "Clé du secret pour l'utilisateur SQL",
      "name": "sql_user_key",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "sql-admin-user",
      "label": "Clé du secret pour l'utilisateur SQL",
      "name": "sql_user_key",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    },
    "storage_account": {
     "currentValue": "stsalesinsightcuxm0611",
     "nuid": "9ffeb04c-bfc1-4847-a5a2-20fc43742da9",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "stsalesinsightcuxm0611",
      "label": "Nom du compte de stockage",
      "name": "storage_account",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "stsalesinsightcuxm0611",
      "label": "Nom du compte de stockage",
      "name": "storage_account",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
